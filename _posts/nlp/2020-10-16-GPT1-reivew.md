---
title:  "GPT1 paper review (작성 중)"
excerpt: "GPT1 리뷰/공부/정리"
toc: true
toc_sticky: true
comments: true
permalink: /project/nlp/gpt1/
categories:
  - NLP
tags:
  - Language Modeling
  - Need to Complete

use_math: true
last_modified_at: 2020-10-16
---

이번 스터디 순서는 GPT1이다. 원문은 [이곳](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)을 참고하자.

# 1. Introduction

Leveraging more than word-level information from unlabeled text, however, is challenging for twomain reasons:
- it is unclear what type of optimization objectives are most effective at learning text representations that are useful for transfer
- there is no consensus on the mosteffective way to transfer these learned representations to the target task

# 2. Related Work

Note: 이 부분에서는 semi-supervised learning for NLP, Unsupervised pre-training에 대한 명확한 차이를 잘 모르겠다. 스터디를 함께 진행하시는 분이 [정리한 글](https://github.com/abooundev/nlp_paper/issues/1)이 있기는 한데, 보더라도 잘 이해가 되진 않는다. 
{: .notice--info}

# 3. 

