---
title:  "GPT2: Language Models are Unsupervised Multitask Learners review"
excerpt: "맥락과 함께 자세히 살펴보는 GPT2 논문 리뷰/설명"
toc: true
toc_sticky: true
permalink: /project/nlp/gpt2-review/
categories:
  - NLP
  - Paper Review
tags:
  - Language Modeling
use_math: true
last_modified_at: 2021-01-06
---

# Intro

GPT2는 대용량 데이터 셋과 엄청나게 큰 모델을 통해 학습한 언어 모델 (language model)로, 다양한 태스크에서 SOTA를 달성하며 zero-shot task trasnfer를 성공적으로 수행해냈다. GPT2 논문을 읽어보며 어떻게 이러한 태스크를 성공적으로 수행했는지 살펴보자. 
영문 표현도 복잡하고, 연구 맥락을 몰라 이해하기가 좀 어려웠지만, 최대한 맥락을 이해하려 노력했고, 적절한 의역 및 모르는 부분은 따로 빼내어 설명을 넣었다.

본 논문은 [다음](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)에서 확인할 수 있다.

# 1. Introduction

기계학습 시스템은 많은 파라미터를 갖는 모델 (high-capacity models), 큰 데이터 셋, 그리고 지도 학습을 조합하여 큰 성공을 거뒀다. 그러나 아직은 다루기 어렵고 데이터 분포와 task specification의 약간의 변화에도 민감하다.

현재의 머신러닝은 좁은 범위에 있어서의 전문가이지 (narrow expert), 모든 것을 다루는 제너럴리스트로 보기는 어렵다.
따라서 본 논문은 다양한 task를 수행할 수 있는 좀 더 일반적인 시스템에 대해 탐구한다.
이를 통해 결국에는 수동으로 데이터셋을 만들고 레이블링을 할 필요가 없게 될 것이다.

머신러닝의 주 접근법은 원하는 task에 대해 맞게 행동하는 학습 셋을 모으고,
이러한 행동을 머신이 따라할 수 있게 하며,
마지막으로 IID test set에서 이의 성능을 측정하는 것이다.

이러한 접근법은 narrow expert에서는 성공적이었지만, 다음과 같이 캡셔닝 모델 (captioning model)에서의 이상한 행동이라던가 (Lake et al.,2017), 

![image](https://user-images.githubusercontent.com/47516855/103776345-a7677080-5072-11eb-980f-324723f27b11.png){: .align-center}{: width="700"}

기계 독해 (reading comprehension)에서의 이상한 행동 이라던가 (Jia & Liang, 2017),

![image](https://user-images.githubusercontent.com/47516855/104025489-10ccb800-5208-11eb-81f9-aabf1aa01773.png){: .align-center}{: width="350"}

이미지 분류 (image classification)에서의 이상한 행동 (Alcorn et al., 2018),

![image](https://user-images.githubusercontent.com/47516855/104032675-d405be80-5211-11eb-91ad-0a13534554d0.png){: .align-center}{: width="600"}

들이 발생하는데, 이는 이들과 입력의 다양성에 의해 발생된다.

본 논문은 현재 시스템에서 관찰되는 일반화 성능 부족에 대한 주 원인이 단일 도메인 데이터셋 (single domain dataset)에 대한 단일 태스크 학습 (single task training) 때문이라고 본다.
현재의 아키텍쳐를 통해 robust한 시스템을 구축하기 위해서는 넓은 범위의 도메인과 테스크에 대한 학습과 평가가 필요하다.
최근에는 이러한 연구를 시작하기 위해 GLUE, decaNLP와 같은 몇몇 벤치마크가 개발되기도 했다.

Multitask leanring은 일반적인 성능을 향상시키기에 좋은 방법이지만, 자연어처리에서의 활용은 거의 연구된 바가 없다.
최근 (Yogtama et al., 2019)는 적당한 성능의 향상을 이끌어 내었고, (McCann et al., 2018)과 (Bowman et al., 2018)의 경우 각 10, 17개의 (dataset, objectvie) 쌍을 통해 주목할만한 결과를 보였다.


Meta-learning 관점에서, 개개의 (dataset, objective) 쌍은 dataset과 objective의 분포로부터 샘플링 된 training example로 볼 수 있다.
현재의 머신러닝 시스템은 일반화를 잘 하는 함수를 사용하기 위해 백개에서 천개의 example이 필요하다.
이는 multitask training이 지금의 방법론과 함께 일반적인 성능을 향상시키기 위해서는 많이 양의 효과적인 training 쌍이 필요하다는 것을 시사한다.
현재 사용하는 기술로 브루트 포스를 사용하는데 필요한 만큼 데이터 셋을 생성하고 목적함수의 설계를 계속 확장하는 것은 매우 어려울 것이다.
이는 multitask learning을 수행하기 위해 추가적인 환경을 탐색하는 이유가 될 것이다.

현재 language task에 대해 최고의 성능을 내는 시스템은 pre-training과 supervised fine-tuning을 조합하여 활용하는 것이다.
이러한 접근법은 긴 역사를 갖고 있는데, transfer의 더욱 유연한 형태로 나아가는 추세이다.

가장 먼저 (Mikolov et al., 2013) (*오른쪽*), (Collobert et al. 2011) (*왼쪽*)과 같이 task-specific한 구조의 input으로 활용되는 word vector가 있었다.

![image](https://user-images.githubusercontent.com/47516855/104325555-1ab62a00-552c-11eb-849f-6b780fc27877.png){: .align-center}{: width="600"}


그 다음에는 (Dai & Le, 2015)(*위*)나  ELMo (Peters et al., 2018) (*아래*)와 같이 RNN을 활용한 contextual representation을 trasnfer learning하는 형태가 있었고,

![image](https://user-images.githubusercontent.com/47516855/104326639-4a196680-552d-11eb-8fa6-a0ab6f7bcd1d.png){: .align-center}{: width="600"}

최근 연구된 GPT-1(Radford et al., 2018), BERT (Devlin et al., 2018)에서는 task-specific한 구조가 더 이상 필요하지 않고, 많은 self-attention block을 transferring 하는 것만으로도 충분함을 보였다.

이러한 연구들은 task를 수행하기 위해 여전히 supervised training을 필요로 한다.
앞선 연구들과는 다른 방향에서 살펴보면, 오직 최소한 혹은 아예 supervised data에 대한 접근이 불가능한 경우에 언어 모델이 commonsense reasoning (Schwartz et al., 2017)이나 sentiment analysis (Radford et al., 2017)과 같은 specific task에서 성공적으로 수행할 수 있음을 증명하였다.

본 논문에서는 방금 살펴본 연구의 두 가지 흐름을 연결하고, transfer의 좀 더 일반적인 방법론을 이어가도록 한다.
본 논문에서는 언어 모델이 zero-shot 환경에서, 어떠한 parameter나 구조의 변화 없이 down-stream task를 수행함을 확인하였다.
이를 통해 zero-shot 환경에서 다양한 범위의 task를 수행하는 언어 모델의 능력을 확인할 수 있었다.

# 2. Approach

본 접근법의 핵심은 언어 모델이다. 언어 모델은 주로 unsupervised distribution estimation의 구조를 갖는다.
언어는 자연적으로 순서가 있으므로, 이의 joint probability를 단어로 나누어 conditional probability의 곱으로 표현하는 것이 당연하다.

$$
p(x) = \displaystyle\prod ^n _1 p(s _n \rvert s _1, ..., s _{n-1})
$$

이러한 접근법은 $p(x)$ 뿐만 아니라 어떠한 conditional form $p(s _{n-k}, ..., s _n \rvert s _1, ..., s _{n-k-1})$의 estimaion과 tractable한 sampling을 가능케한다.
최근 몇년간 Trasnformer와 같이 self-attention 구조를 이용하여 이러한 conditional probability를 계산하는 모델의 표현력에 상당한 개선이 있었다.

단일 작업에 대해 배우는 것은 conditional probability $p(output \rvert input)$를 estimation하는 식의 probabilistic framework로 표현할 수 있다.
일반적인 시스템은 심지어 input이 같은 경우라도 다양한 작업을 수행할 수 있어야 하므로, 이러한 input 뿐만 아니라 task에도 condition이 있어야 한다.
이는 바로, $p(output \rvert input, task)$가 된다.

이는 multitask와 meta-learning에서 널리 수식화되어 왔다. task conditioning은 (Kaiser et al., 2017)에서의 task specific endoer-dercoder와 같이 구조적인 수준에서 구현되거나,

![image](https://user-images.githubusercontent.com/47516855/104333093-332a4280-5534-11eb-89ea-c8bc60445bae.png){: .align-center}{: width="600"}

MAML (Finn et al., 2017)에서의 inner/outer loop optimization framework과 같이 algorithm level에서 구현된다.
그러나 decaNLP에서 예시를 든 것과 같이 언어를 통해 specific task, inputs, output을 symbol sequence의 형태로 표현할 수 있다.
예를 들어, 번역 문제의 경우 *(translate to french, english text, french text)*와 같이 task, input, output 모두 언어의 형태로 표현할 수 있다.
이와 같이 기계독해 역시 *(answer the question, document, question, answer)*로 표현할 수 있다.

decaNLP는 단일 모델 (MQAN)을 학습시켜 이러한 형태의 데이터 셋에 대해 다양한 작업을 수행할 수 있음을 보였다.

![image](https://user-images.githubusercontent.com/47516855/104334380-9cf71c00-5535-11eb-877a-be34ea7ab7aa.png){: .align-center}{: width="800"}

또한, symbol이 모델의 결과가 되는 explicit supervision없이 언어 모델은 원칙적으로 decaNLP의 task로 학습할 수 있다.
Unsupervised objective는 supervised objective와 동일하지만 sequence의 subset에 대해서만 오직 평가가 가능하기 때문에, unsupervised objective의 global minimum 또한 supervised objective의 global minimum이 된다.

이러한 약간의 toy setting에서, (Sutskeveret al., 2015)에서 논의되었던 principled training objective로서의 density estimation에 대한 우려가 사라지게 된다 (side stepped).
대신, 원칙적으로 unsupervised objective를 최적화하는 것이 문제가 된다.

Preliminary experiments를 통해 이러한 toy-ish set up에서 충분히 큰 언어 모델이 multitask learning을 수행할 수 있음을 확인했지만, explicitly supervised approaches보다는 훨씬 느리게 학습한다.

비록 위에서 언급한 well-posed setup으로부터 "현재 사용중인 언어(language in the wild)"의 복잡함까지 큰 발전을 이뤄냈지만, Weston(2016)은 대화의 맥락(context of dialog)을 통해 자연어로부터 직접 배우는 시스템을 개발할 필요하다고 주장했다. 또한, teacher output의 forward prediction에 의한 reward signal없이 QA task를 학습함으로서 이러한 POC를 증명했다 [참고](https://m.blog.naver.com/PostView.nhn?blogId=hist0134&logNo=220916684295&proxyReferer=https:%2F%2Fwww.google.com%2F).

dialog가 매력적인 접근법인 것은 맞으나, 매우 제한되어 있다는 점이 문제가 된다. 인터넷에는 대화형 커뮤니케이션없이 수동적으로 사용할 수있는 방대한 양의 정보가 포함되어 있다. 본 저자들은 충분한 용량을 갖는 언어 모델이 자연어 sequence에서 증명된 task를 수행하고 추론할 수 있을 것이라 추측한다. 만일 추측이 맞다면, 사실상 unsupervised multitask learning을 수행하는 셈이다.

이를 증명하기 위해 넓은 범위의 task에 대해 zero-shot setting으로 언어 모델의 수행 능력을 평가한다.

## 2.1 Training Dataset

대부분의 사전연구는 news article이나 (Jozefowicz et al., 2016), Wikipedia (Merity  et al.,  2016), 소설 책 (Kiroset al., 2015)과 같은 single domain text에 대해 언어 모델을 학습시켰다. 본 논문의 접근법은 가능한 다양한 도메인과 context에서 tasks에 대한 natural language demonstrations를 수집하기위해 가능한 크고 다양한 데이터 셋을 구축하는 것이다.

다양하고 거의 무제한에 가깝게 데이터를 모으는 가장 좋은 방법은 Common Crawl과 같은 웹 크롤링이다. 이러한 archive가 현재 언어 모델 dataset보다 수십배나 많은 데이터 셋을 가지고 있긴 하지만, 품질이 좋지 않다는 것이 문제이다. Trinh & Le (2018)는 Common Crawl을 사용하여 commonsense reasoning을 학습했지만, "대부분의 내용을 이해할 수 없는" 학습 데이터가 많다는 점을 발견했다.

본 논문 역시 이와 비슷한 현상을 발견했다. Trinh & Le (2018)의 실험에서 좋은 결과를 낸 것은 test set인 [Winograd Schema Challenge](https://huggingface.co/datasets/viewer/?dataset=snli)와 유사한 문서를 포함할 때였다. 이러한 접근법이 특정한 task에 대한 성능을 높이는데는 실리적이긴 하지만, 미리 수행하는 작업에 대한 가정을 만드는 것을 피하였다. 

![image](https://user-images.githubusercontent.com/47516855/104456459-08032a00-55ec-11eb-92c1-822ad91c6bb6.png){: .align-center}{: width="800"}
Winograd Schema Challenge는 위 그림과 같이 중의적인 문장을 주고, 단어가 바뀔 때 어떤 뜻이 정답인지를 묻는 task이다. x표시는 dataset-specific bias이다.
{: .notice--info}

이 대신 문서의 품질에 중점을 둔 새로운 web scrape을 만들었다. 이는 사람이 직접 선별하고 필터링 한 것으로, 직접 수동으로 필터링하는 것은 expensive하기 때문에 소셜 미디어 플랫폼인 Reddit에서 최소 3 카르마(일종의 평점) 이상 받은 outbound links를 스크랩했다. 
이는 다른 사람이 이 링크를 흥미, 교육, 아니면 단순히 재미있게 생각하는지에 대한, 일종의 휴리스틱한 지표로 생각할 수 있다.

이에 대한 결과인 WebText는 45M 개의 링크에 대한 부분 집합을 포함하고 있다. HTML response로부터 텍스트를 추출하기 위해 Dragnet (Peters &Lecocq, 2013)과 [Newspaper](https://github.com/codelucas/newspaper) content extractor를 조합하여 사용하였다.

본 논문의 결과는 전부 WebText의 이전버전으로 2017년 이후의 링크는 포함하고 있지 않으며, total 40GB 텍스트를, 8M 조금 넘는 문서에 대해 중복 제거와 휴리스틱한 정제 과정을 거쳤다. 데이터 셋 내의 위키피디아 문서는 다른 데이터 셋에서도 발견할 수 있는 일반적인 셋이므로 학습/테스트 평가간의 중복으로 인해 분석하기가 까다로우므로 전부 삭제하였다.

## 2.2. Input Representation

일반적인 언어 모델은 어떠한 문자열 (string)에 대한 확률과 이의 생성이 가능해야 한다. 현재의 커다란 언어 모델은 소문자, 토큰화, out of vocabulary (OOV) 토큰 문제가 있어 **모델이 사용가능한 문자열의 공간을 제한**한다. Gillicket al. (2015)의 예시처럼 **유니코드 문자열을 UTF-8 바이트 시퀀스로 사용**하는 것은 이러한 요구조건을 깔끔하게 해결하지만, One Billion Word Benchmark (Al-Rfou et al., 2018)과 같은 **대규모의 데이터 셋**에서는 현재의 바이트 단위 (byte-level) 언어 모델은 **단어 단위 (word-level) 언어 모델**과 **경쟁할 급**이 안된다. 이는 본 논문에서 WebText에 대해 일반적인 바이트 단위 언어 모델을 시도했을 때도 비슷한 성능의 차이를 관측할 수 있었다.

Byte Pair Encoding (BPE) (Sennrich et al., 2015)은 단어 단위 언어 모형과 문자 단위 (character-level) 언어 모형 사이의 실용적인 절충안으로, 자주 등장하는 심볼 시퀀스는 단어 단위로, 빈번하지 않는 심볼 시퀀스는 문자 단위로 취급한다. 
이름이 무색하게도 BPE의 구현은 바이트가 아닌 유니코드 코드 포인트에 대해 동작한다.
따라서 모든 유니코드 문자열을 모델링하기 위해 유니코드 심볼의 full space를 필요로 할 것이다.
이를 통해 멀티 심볼을 추가하기도 전에 기본 사전 (base vocabulary)만으로 130,000개가 넘는다는 결론이 나온다.
이는 일반적으로 BPE에서 사용되는 32,000 ~ 64,000 토큰 사전에 비교했을 때 엄청나게 큰 숫자이다.

반면, 바이트 단위 BPE는 기본 사전으로 256의 사이즈만을 필요로 한다. 
그러나 바이트 시퀀스에 대해 직접적으로 BPE를 적용하는 것은 차선책 (sub-optimal)인데, 이는 토큰 사전을 구축하기 위해 휴리스틱에 기반하는 탐욕 빈도 (greedy frequency)를 사용하기 때문이다. BPE를 적용하면 dog와 같은 일반적인 단어의 다양한 변형이 포함되는 것을 볼 수 있는데, 이는 *dog.*, *dog!*, *dog?*와 같이 다양한 베리에이션이 일어나기 때문이다. 
이러한 문제를 피하기 위해, BPE가 어떠한 바이트 시퀀스에 대해서도 character category를 넘어 합쳐지는 것을 방지한다.
그러나 공백(space)에 대해서는 예외를 두는데, 공백은 압축 효율을 엄청나게 상승시키면서 여러개의 사전 토큰에 걸쳐 표현되는 단어를 오직 최소한의 분열을 통해 사전에 추가할 수 있기 때문이다.

이러한 입력 표현 (input representation)은 바이트 단위 접근법의 일반성과 단어 단위 언어모형의 경험적 이점을 결합할 수 있도록 해준다.
이를 통해 어떠한 유니코드 문자열에 확률을 부여할 수 있게 되고, 전처리나 토큰화, 사전 크기와 무관하게 어떠한 데이터셋에 대해서도 GPT2를 평가할 수 있게 된다.

여기서 말하는 Unicode string/byte-level의 차이가 뭔지 모르겠다. 어차피 결과가 똑같을텐데 다르다는 말인가?
{: .notice--danger}

## 2.3. Model

모델에서는 딱히 특별한 것은 없다. Transformer를 사용했고, OpenAI GPT의 구조와 거의 동일하다.
다만 약간의 수정이 있는데, 우선 layer normalization이 각 sub-block의 입력으로 오게 됐고, 마지막 self-attention block 다음에 layer normalization을 하나 더 추가했다.
모델의 깊이에 따른 residual path의 누적을 설명하기 위해 수정된 초기화를 사용하였고, residual layer의 가중치는 이의 개수 $N$의 루트 분의 1인 $\frac{1}{\sqrt N}$로 스케일하였다.
사전의 크기는 50,257로 확장되었고, 시퀀스의 크기 또한 512에서 1024 토큰으로 늘렸다. 배치사이즈는 512이다.

# 3. Experiments


